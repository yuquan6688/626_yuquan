[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html",
    "title": "Hands-on_Ex01a–Geospatial Data Wrangling with R",
    "section": "",
    "text": "Geospatial Data Science is a process of importing, wrangling, integrating, and processing geographically referenced data sets. In this hands-on exercise, I will learn how to perform geospatial data science tasks in R by using sf package.\nBy the end of this hands-on exercise, I will acquire the following competencies:\n\ninstalling and loading sf and tidyverse packages into R environment,\nimporting geospatial data by using appropriate functions of sf package,\nimporting aspatial data by using appropriate function of readr package,\nexploring the content of simple feature data frame by using appropriate Base R and sf functions,\nassigning or transforming coordinate systems by using using appropriate sf functions,\nconverting an aspatial data into a sf data frame by using appropriate function of sf package,\nperforming geoprocessing tasks by using appropriate functions of sf package,\nperforming data wrangling tasks by using appropriate functions of dplyr package and\nperforming Exploratory Data Analysis (EDA) by using appropriate functions from ggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#extracting-the-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#extracting-the-geospatial-data-sets",
    "title": "Hands-on_Ex01a–Geospatial Data Wrangling with R",
    "section": "2.1 Extracting the geospatial data sets",
    "text": "2.1 Extracting the geospatial data sets\nTo get started, create a new folder called Hands-on_Ex in a working directory.\nNext, create a new sub-folder called Hands-on_ex01 in the newly created Hands-on_Ex folder.\nIn the Hands-on_Ex01 folder, create a sub-folder called data. Then, inside the data sub-folder, create two sub-folders and name them geospatial and aspatial respectively.\nPlace Master Plan 2014 Subzone Boundary (Web), Pre-Schools Location and Cycling Path zipped files into geospatial sub-folder and unzipped them. Copy the unzipped files from their respective sub-folders and place them inside geospatial sub-folder."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#extracting-the-geospatial-data-sets-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#extracting-the-geospatial-data-sets-1",
    "title": "Hands-on_Ex01a–Geospatial Data Wrangling with R",
    "section": "2.2 Extracting the geospatial data sets",
    "text": "2.2 Extracting the geospatial data sets\nNow, I will extract the downloaded listing data file. At Downloads folder, cut and paste listing.csv into aspatial sub-folder."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#importing-polygon-feature-data-in-shapefile-format",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#importing-polygon-feature-data-in-shapefile-format",
    "title": "Hands-on_Ex01a–Geospatial Data Wrangling with R",
    "section": "4.1 Importing polygon feature data in shapefile format",
    "text": "4.1 Importing polygon feature data in shapefile format\nThe code chunk below uses st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame. Note that when the input geospatial data is in shapefile format, two arguments will be used, namely: dsn to define the data path and layer to provide the shapefile name. Also note that no extension such as .shp, .dbf, .prj and .shx are needed.\n\nmpsz = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/liyuquan/yuquan6688/626_yuquan/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe message above reveals that the geospatial objects are multipolygon features. There are a total of 323 multipolygon features and 15 fields in mpsz simple feature data frame. mpsz is in svy21 projected coordinates systems. The bounding box provides the x extend and y extend of the data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#importing-polyline-feature-data-in-shapefile-form",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#importing-polyline-feature-data-in-shapefile-form",
    "title": "Hands-on_Ex01a–Geospatial Data Wrangling with R",
    "section": "4.2 Importing polyline feature data in shapefile form",
    "text": "4.2 Importing polyline feature data in shapefile form\nThe code chunk below uses st_read() function of sf package to import CyclingPath shapefile into R as line feature data frame.\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\") %&gt;%\n  st_transform(crs=3414)\n\nReading layer `CyclingPathGazette' from data source \n  `/Users/liyuquan/yuquan6688/626_yuquan/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 4651 features and 19 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11721.1 ymin: 27550.13 xmax: 42809.37 ymax: 49702.59\nProjected CRS: SVY21\n\n\nThe message above reveals that there are a total of 4651 features and 19 fields in cyclingpath sf data frame. The geospatial entities are capture in multilinestring object. Similar to the MP19_SUBZONE_WEB_PL shape file, this data set is in in svy21 projected coordinates system too."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#importing-gis-data-in-kml-format",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#importing-gis-data-in-kml-format",
    "title": "Hands-on_Ex01a–Geospatial Data Wrangling with R",
    "section": "4.3 Importing GIS data in kml format",
    "text": "4.3 Importing GIS data in kml format\nThe PreSchoolsLocation is in kml format. The code chunk below will be used to import the kml into R.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/liyuquan/yuquan6688/626_yuquan/Hands-on_Ex/Hands-on_Ex01/data/geospatial/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe message above reveals that preschool is a point feature data frame. There are a total of 2290 features and 2 fields. Different from the previous two simple feature data frame, preschool is in wgs84 coordinates system."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#working-with-st_geometry",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#working-with-st_geometry",
    "title": "Hands-on_Ex01a–Geospatial Data Wrangling with R",
    "section": "5.1 Working with st_geometry()",
    "text": "5.1 Working with st_geometry()\nThe column in the sf data.frame that contains the geometries is a list of class sfc. We can retrieve the geometry list-column in this case by mpsz$geom or mpsz[[1]], but the more general way uses st_geometry() as shown in the code chunk below.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#working-with-glimpse",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#working-with-glimpse",
    "title": "Hands-on_Ex01a–Geospatial Data Wrangling with R",
    "section": "5.2 Working with glimpse()",
    "text": "5.2 Working with glimpse()\nBeside the basic geospatial feature information, we also would like to learn more about the associated attribute information in the data frame. This is the time you will find glimpse() of dplyr. very handy as shown in the code chunk below.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nglimpse() report reveals the data type of each fields. For example FMEL-UPD_D field is in date data type and X_ADDR, Y_ADDR, SHAPE_L and SHAPE_AREA fields are all in double-precision values."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#working-with-head",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#working-with-head",
    "title": "Hands-on_Ex01a–Geospatial Data Wrangling with R",
    "section": "5.3 Working with head()",
    "text": "5.3 Working with head()\nSometimes we would like to reveal complete information of a feature object, this is the job of head() of Base R\n\nhead(mpsz, n=5) \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#assigning-epsg-code-to-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#assigning-epsg-code-to-a-simple-feature-data-frame",
    "title": "Hands-on_Ex01a–Geospatial Data Wrangling with R",
    "section": "7.1 Assigning EPSG code to a simple feature data frame",
    "text": "7.1 Assigning EPSG code to a simple feature data frame\nOne of the common issue that can happen during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nIn order to assign the correct EPSG code to mpsz data frame, st_set_crs() of sf package is used as shown in the code chunk below.\n\nmpsz &lt;- st_set_crs(mpsz, 3414)\n\nNow, let us check the CSR again by using the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21.",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21.",
    "title": "Hands-on_Ex01a–Geospatial Data Wrangling with R",
    "section": "7.2 Transforming the projection of preschool from wgs84 to svy21.",
    "text": "7.2 Transforming the projection of preschool from wgs84 to svy21.\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nLet us take preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system.\n\nThis is a scenario that st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\nLet us perform the projection transformation by using the code chunk below.\n\npreschool &lt;- st_transform(preschool, \n                              crs = 3414)\n\nNext, let us display the content of preschool sf data frame as shown below.\nNotice that it is in svy21 projected coordinate system now. Furthermore, if you refer to Bounding box:, the values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems.\nNow, let us try to plot the preschool layer ontop of mpsz layer again by using the similar code chunk you used earlier.\n\nplot(st_geometry(mpsz))\nplot(st_geometry(preschool), add = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#importing-the-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#importing-the-aspatial-data",
    "title": "Hands-on_Ex01a–Geospatial Data Wrangling with R",
    "section": "8.1 Importing the aspatial data",
    "text": "8.1 Importing the aspatial data\nSince listings data set is in csv file format, we will use read_csv() of readr package to import listing.csv as shown the code chunk below. The output R object is called listings and it is a tibble data frame.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() of Base R instead of glimpse() is used to do the job.\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,659 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Ensuite …  367042 Belinda   East Region         Tampines          1.35\n 2  71896 B&B  Roo…  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Room 2-n…  367042 Belinda   East Region         Tampines          1.35\n 4 275343 10min wa… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 15 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 294281 5 mins w… 1521514 Elizabeth Central Region      Newton            1.31\n 7 324945 Comforta… 1439258 Kay       Central Region      Bukit Merah       1.29\n 8 330095 Relaxing… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 344803 Budget s…  367042 Belinda   East Region         Tampines          1.35\n10 369141 5mins fr… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,649 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nThe output reveals that listing tibble data frame consists of 4252 rows and 16 columns. Two useful fields we are going to use in the next phase are latitude and longitude. Note that they are in decimal degree format. As a best guess, we will assume that the data is in wgs84 Geographic Coordinate System."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "title": "Hands-on_Ex01a–Geospatial Data Wrangling with R",
    "section": "8.2 Creating a simple feature data frame from an aspatial data frame",
    "text": "8.2 Creating a simple feature data frame from an aspatial data frame\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThings to learn from the arguments above:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\nLet us examine the content of this newly created simple feature data frame.\n\nglimpse(listings_sf)\n\nRows: 3,659\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 29…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 143, NA, 76, NA, NA, 85, NA, NA, 41, 79…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 180, 180, 92,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 131, 17, 5, 60, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.14, 0.27, 0.13, 0.10, 0.80, 0.1…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 58, 58, 7, 58, 58, 5, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 90, 79, 90, 153, 153, 365, 153, 153, 36…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, \"S039…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#diy",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#diy",
    "title": "Hands-on_Ex01a–Geospatial Data Wrangling with R",
    "section": "DIY",
    "text": "DIY\n\nplot(st_geometry(mpsz))\nplot(st_geometry(listings_sf), \n     add = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#use-case-1-land-acquisition-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#use-case-1-land-acquisition-analysis",
    "title": "Hands-on_Ex01a–Geospatial Data Wrangling with R",
    "section": "9.1 Use case 1: Land acquisition analysis",
    "text": "9.1 Use case 1: Land acquisition analysis\n\n9.1.1 The scenario\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the existing cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\n\n\n9.1.2 The solution\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths.\n\nbuffer_cycling &lt;- st_buffer(\n  cyclingpath, dist=5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code chunk below.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nIf you are tidyverse person like me, code chunk below should be used.\n\nbuffer_cycling &lt;- buffer_cycling %&gt;%\n  mutate(AREA = st_area(geometry))\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n3561648 [m^2]\n\n\nWe can also create a plot showing the buffer by a selected planning subzone.\nAssuming that we are interested on the land acquisition in Tampines West planning subzone.\nFirstly, filter() of dplyr package will be used to extract polygon feature of Tampines West by using the code chunk below.\n\nmpsz_selected &lt;- mpsz %&gt;%\n  filter(SUBZONE_N == \"TAMPINES WEST\")\n\nNext, st_intersection() of sf package will be used to clip cycling buffers within Tampines West planning subzone.\n\nbuffer_cycling_selected &lt;- st_intersection(\n  buffer_cycling, mpsz_selected)\n\nLastly, plot() of R Graphic will be used to create the plot as shown below.\n\nplot(st_geometry(buffer_cycling_selected))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#use-case-2-to-determine-the-number-of-pre-schools-by-planning-subzone",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#use-case-2-to-determine-the-number-of-pre-schools-by-planning-subzone",
    "title": "Hands-on_Ex01a–Geospatial Data Wrangling with R",
    "section": "9.2 Use case 2: To determine the number of pre-schools by planning subzone",
    "text": "9.2 Use case 2: To determine the number of pre-schools by planning subzone\n\n9.2.1 The scenario\nThe authority requires a count of pre-schools for each planning subzone to support forward planning. Using R and the sf package, perform the necessary geoprocessing to compute these counts and present the results clearly.\n\n\n9.2.2 The solution\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz$`PreSch Count`&lt;- lengths(st_intersects(mpsz, preschool))\n\nYou can check the summary statistics of the newly derived PreSch Count field by using summary() as shown in the code chunk below.\n\nsummary(mpsz$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nIn the code chunk below, another geoprocessing function of sf package called st_area() is used to derive the area of each planning subzone.\n\nmpsz$Area &lt;- mpsz %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below.\n\nmpsz &lt;- mpsz %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\nIn this section, you will visualise the derive variables by using appropriate Exploratory data Analysis methods of ggplot2.\nFirstly, we will plot a histogram to reveal the distribution of PreSch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the syntax is very easy to use however the output is far from meeting publication quality. Furthermore, the function has limited room for further customisation.\nIn the code chunk below, appropriate ggplot2 functions will be used.\n\nggplot(data=mpsz, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning subzones with a single pre-school, on the other hand, \\nthere are seven planning subzones with at least 30 or more pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\n\nIn the code chunk below, appropriate ggplot2 functions are used to plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\nggplot(data=mpsz, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html",
    "title": "Hands-on_Ex02b–2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Second-order spatial point pattern analysis examines the spatial relationships between points in a pattern, specifically focusing on how the presence of one point influences the location of others. It goes beyond simply describing the overall density of points (first-order effects) by investigating clustering, dispersion, or randomness at various spatial scales.\nUsing appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childecare centres in Singapore.\nThe specific questions we would like to answer are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html",
    "title": "Hand-on Exercise 2a — First-order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis (SPPA) is the evaluation of the pattern or distribution of a set of points on a surface. The points may represent:\n\nevents such as crimes, traffic accidents, or disease onsets, or\nbusiness services (e.g., coffee shops and fast-food outlets) or facilities such as childcare centres and eldercare centres.\n\nFirst-order Spatial Point Pattern Analysis (1st-SPPA) focuses on understanding the intensity or density of points across a study area. It examines how the distribution of points varies over space, essentially identifying trends or patterns in point density. This type of analysis deals with the individual locations of points and their distribution, without considering interactions between them.\nIn essence, 1st-SPPA helps answer questions such as:\n\nWhere are points most densely located within the study area?\nIs point density uniform, or does it vary across space?\nHow spread out is the point pattern?\n\nIn this chapter, you will gain hands-on experience with spatstat to perform two commonly used 1st-SPPA methods:\nThe specific questions we would like to answer are as follows:\n\nAre the childcare centres in Singapore randomly distributed throughout the country?\nIf the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html",
    "title": "Hand-on Exercise 1b — Introduction to Geospatial Analytics",
    "section": "",
    "text": "In general, thematic mapping involves the use of map symbols to visualize selected properties of geographic features that are not naturally visible, such as population, temperature, crime rate, and property prices, just to mention a few of them.\nGeovisualisation, on the other hand, is the process of using visual representations and cartographic techniques to explore, analyze, and communicate geospatial data. It combines elements of cartography, computer science, and information visualization to enhance spatial understanding and knowledge discovery.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#the-data",
    "title": "Hand-on Exercise 1b — Introduction to Geospatial Analytics",
    "section": "3.1 The Data",
    "text": "3.1 The Data\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2019 Subzone Boundary (No Sea) (KML). It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2019.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2024 in csv format (i.e. respopagesextod2024.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore. Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to georeference to Master Plan 2019 Subzone Boundary."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#importing-geospatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#importing-geospatial-data-into-r",
    "title": "Hand-on Exercise 1b — Introduction to Geospatial Analytics",
    "section": "3.2 Importing Geospatial Data into R",
    "text": "3.2 Importing Geospatial Data into R\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PLshapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `/Users/liyuquan/yuquan6688/626_yuquan/Hands-on_Ex/Hands-on_Ex01/data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n3.2.1 Tidying data\nFunction to extract values from the HTML description\n\nextract_kml_field &lt;- function(html_text, field_name) {\n  if (is.na(html_text) || html_text == \"\") return(NA_character_)\n  \n  page &lt;- read_html(html_text)\n  rows &lt;- page %&gt;% html_elements(\"tr\")\n  \n  value &lt;- rows %&gt;%\n    keep(~ html_text2(html_element(.x, \"th\")) == field_name) %&gt;%\n    html_element(\"td\") %&gt;%\n    html_text2()\n  \n  if (length(value) == 0) NA_character_ else value\n}\n\n\nmpsz &lt;- mpsz %&gt;%\n  mutate(\n    REGION_N = map_chr(Description, extract_kml_field, \"REGION_N\"),\n    PLN_AREA_N = map_chr(Description, extract_kml_field, \"PLN_AREA_N\"),\n    SUBZONE_N = map_chr(Description, extract_kml_field, \"SUBZONE_N\"),\n    SUBZONE_C = map_chr(Description, extract_kml_field, \"SUBZONE_C\")\n  ) %&gt;%\n  select(-Name, -Description) %&gt;%\n  relocate(geometry, .after = last_col())\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 332 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 10 features:\n         REGION_N    PLN_AREA_N           SUBZONE_N SUBZONE_C\n1  CENTRAL REGION   BUKIT MERAH          DEPOT ROAD    BMSZ12\n2  CENTRAL REGION   BUKIT MERAH         BUKIT MERAH    BMSZ02\n3  CENTRAL REGION        OUTRAM           CHINATOWN    OTSZ03\n4  CENTRAL REGION DOWNTOWN CORE             PHILLIP    DTSZ04\n5  CENTRAL REGION DOWNTOWN CORE       RAFFLES PLACE    DTSZ05\n6  CENTRAL REGION        OUTRAM        CHINA SQUARE    OTSZ04\n7  CENTRAL REGION   BUKIT MERAH         TIONG BAHRU    BMSZ10\n8  CENTRAL REGION DOWNTOWN CORE    BAYFRONT SUBZONE    DTSZ12\n9  CENTRAL REGION   BUKIT MERAH TIONG BAHRU STATION    BMSZ04\n10 CENTRAL REGION DOWNTOWN CORE       CLIFFORD PIER    DTSZ06\n                         geometry\n1  MULTIPOLYGON Z (((103.8145 ...\n2  MULTIPOLYGON Z (((103.8221 ...\n3  MULTIPOLYGON Z (((103.8438 ...\n4  MULTIPOLYGON Z (((103.8496 ...\n5  MULTIPOLYGON Z (((103.8525 ...\n6  MULTIPOLYGON Z (((103.8486 ...\n7  MULTIPOLYGON Z (((103.8311 ...\n8  MULTIPOLYGON Z (((103.8589 ...\n9  MULTIPOLYGON Z (((103.8283 ...\n10 MULTIPOLYGON Z (((103.8552 ..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#importing-attribute-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#importing-attribute-data-into-r",
    "title": "Hand-on Exercise 1b — Introduction to Geospatial Analytics",
    "section": "3.3 Importing Attribute Data into R",
    "text": "3.3 Importing Attribute Data into R\nNext, we will import respopagesextod2024.csv file into RStudio and save the file into an tibble dataframe called popdata.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/respopagesextod2024.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#data-preparation",
    "title": "Hand-on Exercise 1b — Introduction to Geospatial Analytics",
    "section": "3.4 Data Preparation",
    "text": "3.4 Data Preparation\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n3.4.1 Data wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2024 &lt;- popdata %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n3.4.2 Joining the attribute data and geospatial data\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2024 &lt;- popdata2024 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2024 &lt;- left_join(mpsz, popdata2024,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nwrite_rds(mpsz_pop2024, \"data/mpsz_pop2024.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#plotting-a-choropleth-map-quickly-by-using-qtm",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#plotting-a-choropleth-map-quickly-by-using-qtm",
    "title": "Hand-on Exercise 1b — Introduction to Geospatial Analytics",
    "section": "4.1 Plotting a choropleth map quickly by using qtm()",
    "text": "4.1 Plotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(shp = mpsz_pop2024, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "title": "Hand-on Exercise 1b — Introduction to Geospatial Analytics",
    "section": "4.2 Creating a choropleth map by using tmap’s elements",
    "text": "4.2 Creating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\", \n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(frame = TRUE) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scalebar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n4.2.1 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_polygons(), tm_symbols(), tm_lines(), tm_raster() and tm_text().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2024) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n4.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2024)+\n  tm_polygons(fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is blues3 of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n4.2.3 Drawing a choropleth map using tm_fill() and *tm_border()**\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the polygon features onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2024)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders() will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2024)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders()\n\n\n\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe fill_alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside fill_alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\ntm_shape(mpsz_pop2024)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(col = \"grey60\",\n             lwd = 0.1,\n             lty = \"dashed\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#data-classification-methods-of-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#data-classification-methods-of-tmap",
    "title": "Hand-on Exercise 1b — Introduction to Geospatial Analytics",
    "section": "4.3 Data classification methods of tmap",
    "text": "4.3 Data classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n4.3.1 Plotting choropleth maps with built-in classification methods\nhe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"equal\",\n                n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\n\nDIY1\n\n# pretty \ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(style = \"pretty\", n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n# equal \ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(style = \"equal\", n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n# quantile \ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(style = \"quantile\", n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n# sd \ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(style = \"sd\", n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n# kmeans \ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(style = \"kmeans\", n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n# hclust \ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(style = \"hclust\", n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n# bclust \ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(style = \"bclust\", n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\nCommittee Member: 1(1) 2(1) 3(1) 4(1) 5(1) 6(1) 7(1) 8(1) 9(1) 10(1)\nComputing Hierarchical Clustering\n\n\n\n\n\n\n\n\n# fisher \ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(style = \"fisher\", n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n# jenks \ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(style = \"jenks\", n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nDIY2\n\n# n = 2\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(style = \"quantile\", n = 2)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n# n = 6\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(style = \"quantile\", n = 6)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n# n = 10\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(style = \"quantile\", n = 10)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n# n = 20\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(style = \"quantile\", n = 20)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.3.2 Plotting choropleth map with custome break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_scale_intervals(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2024$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1905  0.7450  0.8377  0.8738  0.9366 12.7500      94 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2024)+\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00))) +\n  tm_borders(fill_alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#colour-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#colour-scheme",
    "title": "Hand-on Exercise 1b — Introduction to Geospatial Analytics",
    "section": "4.4 Colour Scheme",
    "text": "4.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package. ### 4.4.1 Using ColourBrewer palette\nTo change the colour, we assign the preferred colour to palette argument of values as shown in the code chunk below.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"-brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n4.4.2 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar(), tm_grid() and tm_credit() are used to add compass, scale bar, grid lines and data sources onto the choropleth map.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5)) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scalebar() +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: data.gov.sg & singstat\",\n             position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#map-layout",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#map-layout",
    "title": "Hand-on Exercise 1b — Introduction to Geospatial Analytics",
    "section": "4.5 Map Layout",
    "text": "4.5 Map Layout\nMap layout refers to the combination of all map elements into a cohensive map. It includes the map background, frame, typography, scale, aspect ratio, margins, and more.\nWe can customize the map layout using the tm_layout() function. In this section, we cover the most often used arguments of this function using the dependency choropleth map as example.\n\n4.5.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_pos_auto_in() +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scalebar() +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: data.gov.sg & singstat\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n4.5.2 Map style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"-brewer.greens\")) + \n  tm_borders(fill_alpha = 0.5) + \n  tmap_style(\"natural\")\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#by-assigning-multiple-values-to-at-least-one-of-the-aesthetic-arguments",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#by-assigning-multiple-values-to-at-least-one-of-the-aesthetic-arguments",
    "title": "Hand-on Exercise 1b — Introduction to Geospatial Analytics",
    "section": "5.1 By assigning multiple values to at least one of the aesthetic arguments",
    "text": "5.1 By assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by assigning two variables to the visual variable (i.e. fill).\n\ntm_shape(mpsz_pop2024) + \n  tm_polygons(\n    fill = c(\"YOUNG\", \"AGED\"),\n    fill.legend = \n      tm_legend(position = tm_pos_in(\n        \"right\", \"bottom\")),\n    fill.scale = tm_scale_intervals(\n      style = \"equal\", \n      n = 5,\n      values = \"brewer.blues\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tmap_style(\"natural\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#by-arrange-multiples-choropleth-maps-in-a-grid-layout",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#by-arrange-multiples-choropleth-maps-in-a-grid-layout",
    "title": "Hand-on Exercise 1b — Introduction to Geospatial Analytics",
    "section": "5.2 By arrange multiples choropleth maps in a grid layout",
    "text": "5.2 By arrange multiples choropleth maps in a grid layout\nIn this example, multiple choropleth maps are created and tmap_arrnage() is used to arrnage them in a grid layout.\n\nyoungmap &lt;- tm_shape(mpsz_pop2024)+ \n  tm_polygons(fill = \"YOUNG\",\n              fill.legend = tm_legend(\n                position = tm_pos_in(\n                  \"right\", \"bottom\"),\n                  item.height = 0.8),\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\", \n                values = \"brewer.blues\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Distribution of young population\")\n                \nagedmap &lt;- tm_shape(mpsz_pop2024)+ \n  tm_polygons(fill = \"AGED\",\n              fill.legend = tm_legend(\n                position = tm_pos_in(\n                  \"right\", \"bottom\"),\n                item.height = 0.8),\n              fill.scale = tm_scale_intervals(\n              style = \"quantile\", \n              values = \"brewer.blues\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Distribution of aged population\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#by-defining-a-group-by-variable-in-tm_facets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#by-defining-a-group-by-variable-in-tm_facets",
    "title": "Hand-on Exercise 1b — Introduction to Geospatial Analytics",
    "section": "5.3 By defining a group-by variable in tm_facets()",
    "text": "5.3 By defining a group-by variable in tm_facets()\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2024) +\n  tm_fill(fill = \"DEPENDENCY\",\n          fill.scale = tm_scale_intervals(\n            style = \"quantile\",\n            values = \"brewer.blues\")) + \n  tm_facets(by = \"REGION_N\",\n            nrow = 2, \n            ncols = 3,\n            free.coords=TRUE, \n            drop.units=TRUE) +\n  tm_layout(legend.show = TRUE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(fill_alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#reference",
    "title": "Hand-on Exercise 1b — Introduction to Geospatial Analytics",
    "section": "9 Reference",
    "text": "9 Reference\n\n9.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n9.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n9.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geospatial Analytics and Applications",
    "section": "",
    "text": "Welcome to Yuquan’s Geospatial Analytics and Applications Website!\nHere, you’ll find all the coursework I’ve completed for the ISSS626 Geospatial Analytics and Applications course, including Hands-on Exercises, In-Class Exercises, Take-home Exercises, and the Group Project.\nThis website serves as a portfolio of my learning journey in geospatial analytics, where I explore spatial data, apply GIS techniques, and practice visualization methods to uncover geographic patterns and insights. Feel free to browse through the exercises and projects to see how I apply geospatial methods to real-world problems!\n\n\n\n\n\n\n  \n    Last Post\n    \n      (You can see all the assignments through this link)\n    \n  \n\n\n  \n    🔔 NEW (8/30) – \n    Hands-on Exercise 1a and \n     Hands-on Exercise 1b are published!\n     \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHand-on Exercise 2a — First-order Spatial Point Patterns Analysis Methods\n\n\n\nLi Yuquan\n\n\nSep 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on_Ex02b–2nd Order Spatial Point Patterns Analysis Methods\n\n\n\nLi Yuquan\n\n\nSep 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nHand-on Exercise 1b — Introduction to Geospatial Analytics\n\n\n\nLi Yuquan\n\n\nAug 29, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#mapping-the-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#mapping-the-geospatial-data-sets",
    "title": "Hand-on Exercise 2a — First-order Spatial Point Patterns Analysis Methods",
    "section": "4.1 Mapping the geospatial data sets",
    "text": "4.1 Mapping the geospatial data sets\nAfter checking the referencing system of each geospatial data data frame, it is also useful for us to plot a map to show their spatial patterns.\n\nDIY 1\n\ntm_shape(mpsz_sf) +\n  tm_polygons() +\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\nNotice that all the geospatial layers are within the same map extend. This shows that their referencing system and coordinate values are referred to similar spatial context. This is very important in any geospatial analysis.\nAlternatively, we can also prepare an interactive point symbol map by using the code chunk below.\n\ntmap_mode('view')\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\ntmap_mode('plot')\n\nNotice that at the interactive mode, tmap is using leaflet for R API. The advantage of this interactive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, you can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\nAlways remember to switch back to plot mode after the interactive map. This is because, each interactive mode will consume a connection. You should also avoid displaying ecessive numbers of interactive maps (i.e. not more than 10) in one RMarkdown document when publish on Netlify."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-sf-data-frames-to-ppp-class",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-sf-data-frames-to-ppp-class",
    "title": "Hand-on Exercise 2a — First-order Spatial Point Patterns Analysis Methods",
    "section": "5.1 Converting sf data frames to ppp class",
    "text": "5.1 Converting sf data frames to ppp class\nspatstat requires the point event data in ppp object form. The code chunk below uses [as.ppp()] of spatstat package to convert childcare_sf to ppp format.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nNext, class() of Base R will be used to verify the object class of childcare_ppp.\n\nclass(childcare_ppp)\n\n[1] \"ppp\"\n\n\ncan take a quick look at the summary statistics of the newly converted ppp object by using the code chunk below.\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nMark variables: Name, Description\nSummary:\n     Name           Description       \n Length:1925        Length:1925       \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#creating-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#creating-owin-object",
    "title": "Hand-on Exercise 2a — First-order Spatial Point Patterns Analysis Methods",
    "section": "5.2 Creating owin object",
    "text": "5.2 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below, as.owin() of spatstat is used to covert mpsz_sf into owin object of spatstat.\n\nsg_owin &lt;- as.owin(mpsz_cl)\n\nAgain, class() will be used to verify the object class of sg_owin.\n\nclass(sg_owin)\n\n[1] \"owin\"\n\n\nThe result above confirmed that sg_owin is indeed in owin object.\nsg_owin object can be displayed by using plot() function.\n\nplot(sg_owin)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#combining-point-events-object-and-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#combining-point-events-object-and-owin-object",
    "title": "Hand-on Exercise 2a — First-order Spatial Point Patterns Analysis Methods",
    "section": "5.3 Combining point events object and owin object",
    "text": "5.3 Combining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nchildcareSG_ppp\n\nMarked planar point pattern: 1925 points\nMark variables: Name, Description \nwindow: polygonal boundary\nenclosing rectangle: [2667.54, 55941.94] x [21448.47, 50256.33] units"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#perform-the-clark-evans-test-without-csr",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#perform-the-clark-evans-test-without-csr",
    "title": "Hand-on Exercise 2a — First-order Spatial Point Patterns Analysis Methods",
    "section": "6.1 Perform the Clark-Evans test without CSR",
    "text": "6.1 Perform the Clark-Evans test without CSR\nclarkevans.test() of spatstat.explore package support two Clark-Evans test, namely: without CRS and with CRS. In the code chunk below, Clark-Evans test without CSR method is used.\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"))\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.53532, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\nQuiz\nStatistical conclusion: Clark–Evans R = 0.535 (R=1 random, R&lt;1 clustered, R&gt;1 regular). p &lt; 2.2e-16 with α=0.05 ⇒ reject H₀ (CSR). The childcare centres form a significantly clustered pattern within the study window. The effect size is substantial (R≈0.54), indicating strong clustering rather than mild deviation from randomness.\nBusiness communication: The spatial analysis shows that childcare centres are concentrated in hotspots rather than evenly spread across Singapore. This clustering likely reflects demand concentrations (population density, transport access, HDB estates) but also suggests potential service gaps in less-served areas."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#perform-the-clark-evans-test-with-csr",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#perform-the-clark-evans-test-with-csr",
    "title": "Hand-on Exercise 2a — First-order Spatial Point Patterns Analysis Methods",
    "section": "6.2 Perform the Clark-Evans test with CSR",
    "text": "6.2 Perform the Clark-Evans test with CSR\nIn the code chunk below, the argument method = “MonteCarlo” is used. In this case, the p-value for the test is computed by comparing the observed value of R to the results obtained from nsim (i.e. 39, 99, 999) simulated realisations of Complete Spatial Randomness conditional on the observed number of points.\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                method=\"MonteCarlo\",\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 99 simulations of CSR with fixed n\n\ndata:  childcareSG_ppp\nR = 0.53532, p-value = 0.01\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\nQuiz\nStatistical conclusion: Clark–Evans R = 0.53532 (&lt; 1). With Monte Carlo simulation (nsim = 99), the test produced a p-value = 0.01 under the alternative “clustered.” At the 95% confidence level (α = 0.05), we reject H₀ (CSR).\nBusiness communication: The childcare network is not balanced spatially; targeted expansion into underserved regions would help improve coverage and equity of access."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#working-with-automatic-bandwidth-selection-method",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#working-with-automatic-bandwidth-selection-method",
    "title": "Hand-on Exercise 2a — First-order Spatial Point Patterns Analysis Methods",
    "section": "7.1 Working with automatic bandwidth selection method",
    "text": "7.1 Working with automatic bandwidth selection method\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_SG_diggle &lt;- density(\n  childcareSG_ppp,\n  sigma=bw.diggle,\n  edge=TRUE,\n  kernel=\"gaussian\") \n\nThe output of density() of spatstat is an im class, represents a two-dimensional pixel image. It’s a class used to store and manipulate raster data, where the spatial domain is divided into a grid of rectangular pixels. Each pixel has an associated value, which can be numerical or a factor.\nThe plot() function of Base R is then used to display the kernel density derived.\n\nplot(kde_SG_diggle)\n\n\n\n\n\n\n\n\n\nsummary(kde_SG_diggle)\n\nreal-valued pixel image\n128 x 128 pixel array (ny, nx)\nenclosing rectangle: [2667.538, 55941.94] x [21448.47, 50256.33] units\ndimensions of each pixel: 416 x 225.0614 units\nImage is defined on a subset of the rectangular grid\nSubset area = 669941961.12249 square units\nSubset area fraction = 0.437\nPixel values (inside window):\n    range = [-5.824417e-21, 3.063698e-05]\n    integral = 1927.788\n    mean = 2.877545e-06\n\n\ncan retrieve the bandwidth used to compute the kde layer by using the code chunk below.\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n295.9712"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#rescalling-kde-values",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#rescalling-kde-values",
    "title": "Hand-on Exercise 2a — First-order Spatial Point Patterns Analysis Methods",
    "section": "7.2 Rescalling KDE values",
    "text": "7.2 Rescalling KDE values\nIn the code chunk below, rescale.ppp() is used to covert the unit of measurement from meter to kilometer.\n\nchildcareSG_ppp_km &lt;- rescale.ppp(\n  childcareSG_ppp, 1000, \"km\")\n\nNow, we can re-run density() using the resale data set and plot the output kde map.\n\nkde_childcareSG_km &lt;- density(childcareSG_ppp_km,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\nNext, plot() is used to plot the kde object as shown below.\n\nplot(kde_childcareSG_km)\n\n\n\n\n\n\n\n\nNotice that output image looks identical to the earlier version, the only changes in the data values (refer to the legend)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#working-with-different-automatic-badwidth-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#working-with-different-automatic-badwidth-methods",
    "title": "Hand-on Exercise 2a — First-order Spatial Point Patterns Analysis Methods",
    "section": "7.3 Working with different automatic badwidth methods",
    "text": "7.3 Working with different automatic badwidth methods\nBeside bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\nLet us take a look at the bandwidth return by these automatic bandwidth calculation methods by using the code chunk below.\n\nbw.CvL(childcareSG_ppp_km)\n\n   sigma \n4.357209 \n\n\n\nbw.scott(childcareSG_ppp_km)\n\n sigma.x  sigma.y \n2.159749 1.396455 \n\n\n\nbw.ppl(childcareSG_ppp_km)\n\n   sigma \n0.378997 \n\n\n\nbw.diggle(childcareSG_ppp_km)\n\n    sigma \n0.2959712 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because past experience shown that it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\nThe code chunk beow will be used to compare the output of using bw.diggle and bw.ppl methods.\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp_km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG_km, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#working-with-different-kernel-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#working-with-different-kernel-methods",
    "title": "Hand-on Exercise 2a — First-order Spatial Point Patterns Analysis Methods",
    "section": "7.4 Working with different kernel methods",
    "text": "7.4 Working with different kernel methods\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\nThe code chunk below will be used to compute three more kernel density estimations by using these three kernel function.\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#computing-kde-by-using-fixed-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#computing-kde-by-using-fixed-bandwidth",
    "title": "Hand-on Exercise 2a — First-order Spatial Point Patterns Analysis Methods",
    "section": "8.1 Computing KDE by using fixed bandwidth",
    "text": "8.1 Computing KDE by using fixed bandwidth\nNext, you will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp_kmobject is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_fb &lt;- density(childcareSG_ppp_km,\n                              sigma=0.6, \n                              edge=TRUE,\n                              kernel=\"gaussian\")\nplot(kde_childcareSG_fb)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#computing-kde-by-using-adaptive-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#computing-kde-by-using-adaptive-bandwidth",
    "title": "Hand-on Exercise 2a — First-order Spatial Point Patterns Analysis Methods",
    "section": "8.2 Computing KDE by using adaptive bandwidth",
    "text": "8.2 Computing KDE by using adaptive bandwidth\nFixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\nIn this section, you will learn how to derive adaptive kernel density estimation by using density.adaptive()of spatstat.\n\nkde_childcareSG_ab &lt;- adaptive.density(\n  childcareSG_ppp_km, \n  method=\"kernel\")\nplot(kde_childcareSG_ab)\n\n\n\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG_fb, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_ab, main = \"Adaptive bandwidth\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-gridded-output-into-raster",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-gridded-output-into-raster",
    "title": "Hand-on Exercise 2a — First-order Spatial Point Patterns Analysis Methods",
    "section": "9.1 Converting gridded output into raster",
    "text": "9.1 Converting gridded output into raster\nNext, we will convert the im kernal density objects into SpatRaster object by using rast() of terrapackage.\n\nkde_childcareSG_bw_terra &lt;- rast(kde_childcareSG_km)\n\nAgain, class() is used to verify if kde_childcareSG_bw_terra data are belong to SpatRaster class.\n\nclass(kde_childcareSG_bw_terra)\n\n[1] \"SpatRaster\"\nattr(,\"package\")\n[1] \"terra\"\n\n\nYes, it is indeed in SpatRaster class.\nLet us take a look at the properties of kde_childcareSG_bw_terra .\n\nkde_childcareSG_bw_terra\n\nclass       : SpatRaster \nsize        : 128, 128, 1  (nrow, ncol, nlyr)\nresolution  : 0.4162063, 0.2250614  (x, y)\nextent      : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncoord. ref. :  \nsource(s)   : memory\nname        :         lyr.1 \nmin value   : -4.314789e-15 \nmax value   :  3.063698e+01 \nunit        :            km \n\n\nNotice that the coordicates reference (i.e. coord. ref.) is in SVY21 now."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#plotting-kde-map-with-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#plotting-kde-map-with-tmap",
    "title": "Hand-on Exercise 2a — First-order Spatial Point Patterns Analysis Methods",
    "section": "9.3 Plotting KDE map with tmap",
    "text": "9.3 Plotting KDE map with tmap\nFinally, we will display the raster in cartographic quality map using tmap package.\n\ntm_shape(kde_childcareSG_bw_terra) + \n  tm_raster(col.scale = \n              tm_scale_continuous(\n                values = \"viridis\"),\n            col.legend = tm_legend(\n            title = \"Density values\",\n            title.size = 0.7,\n            text.size = 0.7,\n            bg.color = \"white\",\n            bg.alpha = 0.7,\n            position = tm_pos_in(\n              \"right\", \"bottom\"),\n            frame = TRUE)) +\n  tm_graticules(labels.size = 0.7) +\n  tm_compass() +\n  tm_layout(scale = 1.0)\n\n\n\n\n\n\n\n\nNotice that the raster values are encoded explicitly onto the raster pixel using the values in “layer.1” field."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#geospatial-data-wrangling-1",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#geospatial-data-wrangling-1",
    "title": "Hand-on Exercise 2a — First-order Spatial Point Patterns Analysis Methods",
    "section": "10.1 Geospatial data wrangling",
    "text": "10.1 Geospatial data wrangling\n\n# the code chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\n# It is always a good practice to review the extracted areas. The code chunk below will be used to plot the extracted planning areas.\n\npar(mfrow=c(2,2))\nplot(st_geometry(pg), main = \"Ponggol\")\nplot(st_geometry(tm), main = \"Tampines\")\nplot(st_geometry(ck), main = \"Choa Chu Kang\")\nplot(st_geometry(jw), main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n# Creating owin object\n# Now, we will convert these sf objects into owin objects that is required by spatstat.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n# Combining point events object and owin object\nchildcare_pg_ppp = childcare_ppp[pg_owin]\nchildcare_tm_ppp = childcare_ppp[tm_owin]\nchildcare_ck_ppp = childcare_ppp[ck_owin]\nchildcare_jw_ppp = childcare_ppp[jw_owin]\n\n# Next, rescale.ppp() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\n# The code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(unmark(childcare_pg_ppp.km), \n  main=\"Punggol\")\nplot(unmark(childcare_tm_ppp.km), \n  main=\"Tampines\")\nplot(unmark(childcare_ck_ppp.km), \n  main=\"Choa Chu Kang\")\nplot(unmark(childcare_jw_ppp.km), \n  main=\"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#clark-and-evans-test",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#clark-and-evans-test",
    "title": "Hand-on Exercise 2a — First-order Spatial Point Patterns Analysis Methods",
    "section": "10.2 Clark and Evans Test",
    "text": "10.2 Clark and Evans Test\n\n10.2.1 Choa Chu Kang planning area\nIn the code chunk below, clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centre in Choa Chu Kang planning area.\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.84097, p-value = 0.008866\nalternative hypothesis: two-sided\n\n\n\n\n10.2.2 Tampines planning area\nIn the code chunk below, the similar test is used to analyse the spatial point patterns of childcare centre in Tampines planning area.\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.66817, p-value = 6.58e-12\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#computing-kde-surfaces-by-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#computing-kde-surfaces-by-planning-area",
    "title": "Hand-on Exercise 2a — First-order Spatial Point Patterns Analysis Methods",
    "section": "10.3 10.3 Computing KDE surfaces by planning area",
    "text": "10.3 10.3 Computing KDE surfaces by planning area\nThe code chunk below will be used to compute the KDE of these four planning area. bw.diggle method is used to derive the bandwidth of each\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#choa-chu-kang-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#choa-chu-kang-planning-area",
    "title": "Hands-on_Ex02b–2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.1 Choa Chu Kang planning area",
    "text": "5.1 Choa Chu Kang planning area\n\n# Computing G-function estimation\nset.seed(1234)\n\nThe code chunk below is used to compute G-function using Gest() of spatat package.\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n5.1.1 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-fucntion\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_CK.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#tampines-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#tampines-planning-area",
    "title": "Hands-on_Ex02b–2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.2 Tampines planning area",
    "text": "5.2 Tampines planning area\n\n5.2.1 Computing G-function estimation\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\n\n\n\n5.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#choa-chu-kang-planning-area-1",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#choa-chu-kang-planning-area-1",
    "title": "Hands-on_Ex02b–2nd Order Spatial Point Patterns Analysis Methods",
    "section": "6.1 Choa Chu Kang planning area",
    "text": "6.1 Choa Chu Kang planning area\n\n6.1.1 Computing F-function estimation\nThe code chunk below is used to compute F-function using Fest() of spatat package.\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#performing-complete-spatial-randomness-test-2",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#performing-complete-spatial-randomness-test-2",
    "title": "Hands-on_Ex02b–2nd Order Spatial Point Patterns Analysis Methods",
    "section": "6.2 Performing Complete Spatial Randomness Test",
    "text": "6.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-fucntion\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_CK.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#tampines-planning-area-1",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#tampines-planning-area-1",
    "title": "Hands-on_Ex02b–2nd Order Spatial Point Patterns Analysis Methods",
    "section": "6.3 Tampines planning area",
    "text": "6.3 Tampines planning area\n\n6.3.1 Computing F-function estimation\nMonte Carlo test with F-fucntion\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\n\n\n6.3.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#choa-chu-kang-planning-area-2",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#choa-chu-kang-planning-area-2",
    "title": "Hands-on_Ex02b–2nd Order Spatial Point Patterns Analysis Methods",
    "section": "7.1 Choa Chu Kang planning area",
    "text": "7.1 Choa Chu Kang planning area\n\n7.1.1 Computing K-fucntion estimate\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#performing-complete-spatial-randomness-test-4",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#performing-complete-spatial-randomness-test-4",
    "title": "Hands-on_Ex02b–2nd Order Spatial Point Patterns Analysis Methods",
    "section": "7.1.2 Performing Complete Spatial Randomness Test",
    "text": "7.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#tampines-planning-area-2",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#tampines-planning-area-2",
    "title": "Hands-on_Ex02b–2nd Order Spatial Point Patterns Analysis Methods",
    "section": "7.2 Tampines planning area",
    "text": "7.2 Tampines planning area\n\n7.2.1 Computing K-fucntion estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n7.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#choa-chu-kang-planning-area-3",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#choa-chu-kang-planning-area-3",
    "title": "Hands-on_Ex02b–2nd Order Spatial Point Patterns Analysis Methods",
    "section": "8.1 Choa Chu Kang planning area",
    "text": "8.1 Choa Chu Kang planning area\n\n8.1.1  Computing L Fucntion estimation\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n8.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#tampines-planning-area-3",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#tampines-planning-area-3",
    "title": "Hands-on_Ex02b–2nd Order Spatial Point Patterns Analysis Methods",
    "section": "8.2 Tampines planning area",
    "text": "8.2 Tampines planning area\n\n8.2.1 Computing L-fucntion estimate\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n8.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below will be used to perform the hypothesis testing.\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  }
]